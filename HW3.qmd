---
title: "HW3"
format: html
---

In this example, I try to predict if a certain policy is discussing a certain topic on the basis of the text in that policy. To do so I use quanteda to create a document-feature matrix from the text of each policy, such that each row is a policy and each column is a word, thus, p>>n. However, I filter to only words which appear in more than 50 policies (or roughly 5% of all policies), which reduces p<n. Then I train an RF classifier to predict if a policy discusses the topic (3 are used here as examples) based on the words used in the policy. 

```{r}

library(readxl)
library(tidyverse)

# download data from Bay Adapt Github
# url <- "https://github.com/BCDC-GIS/Bay-Adapt-Currents/blob/e8e4ec0ad1ee6888070975a138a3d7d075c1a40f/Sea%20Level%20Rise%20in%20General%20Plans/Cities.xlsx?raw=true"

# download.file(url, destfile = "data/Cities_Simplified.xlsx")

cities_data <- read_excel("data/Cities_Simplified.xlsx")[,1:41]

colnames(cities_data) <- c('city',
                           'county', 
                           'doc_type',
                           'year',
                           'element',
                           'policy',
                           'program',
                           'text',
                           'aff_housing',
                           'beach',
                           'building_code',
                           'community_engage',
                           'contamination',
                           'coordination',
                           'cult_hist_pres',
                           'development',
                           'econ_jobs',
                           'education_outreach',
                           'emergency',
                           'erosion',
                           'expenditures',
                           'funding',
                           'planning',
                           'habitat_env_qual',
                           'infrastructure',
                           'managed_retreat',
                           'mapping',
                           'levees_seawall',
                           'nature_based',
                           'open_space',
                           'public_health',
                           'research_monitor',
                           'training',
                           'transport_mobility',
                           'utilities',
                           'vulnerable_populations',
                           'water_quality',
                           'wetlands',
                           'flood_stormwater',
                           'groundwater',
                           'slr_mentioned'
                           ) 

# mutate across everything between aff_housing and slr_mentioned to be factors, converting "-" or NA to 0 and "1" to 1

cities_data <- cities_data |> 
  mutate(across(aff_housing:slr_mentioned, ~ case_when(. == "1" ~ 1,
                                                        TRUE ~ 0))) |> 
  mutate(across(aff_housing:slr_mentioned, as.factor)) |> 
  mutate(across(city:element, as.factor))
```

```{r}
library(quanteda)
library(randomForest)

cities_text <- cities_data %>%
  pull(text)

slr_docvar <- cities_data %>%
  select(aff_housing:slr_mentioned)


# convert cities_data$text to a corpus
cities_dfm <- corpus(cities_text, docvars=slr_docvar) %>% 
  tokens(remove_punct = TRUE) %>%
  tokens_remove(stopwords("en")) %>% 
  dfm() %>% 
  dfm_trim(min_termfreq = 50)

dfm_df <- convert(cities_dfm, to='data.frame') %>% 
  select(-doc_id)

fs_rf <- randomForest(x = dfm_df, y = docvars(cities_dfm, "flood_stormwater"), ntree = 100); fs_rf
dev_rf <- randomForest(x = dfm_df, y = docvars(cities_dfm, "development"), ntree = 100); dev_rf
coord_rf <- randomForest(x = dfm_df, y = docvars(cities_dfm, "coordination"), ntree = 100); coord_rf

varImpPlot(fs_rf)
varImpPlot(dev_rf)
varImpPlot(coord_rf)
```

In terms of model performance, these have pretty low error which I am satisfied with. However for some of them this is a bit of a degenerate example as it turns out that the topic of flooding is mostly predicted on the basis of 'flood' or 'flooding'. However it is more interesting for coordination, where "agencies", "regional", "county" predominate "coordinate" as important words. 

